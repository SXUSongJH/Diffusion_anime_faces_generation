# Diffusion Anime Faces Generation

This project implements a Diffusion model for generating high-quality anime character portraits. The goal is to train a deep learning model that can create diverse and visually appealing anime-style face illustrations.

## Project Overview

The main objective of this project is to train and implement a Diffusion model specifically designed for generating anime character portraits. Diffusion models have shown remarkable capabilities in image generation tasks, and this project applies this technology to the specific domain of anime-style artwork.

## Installation and Usage

Follow these steps to set up and run the project:

```bash
# Clone the repository
git clone https://github.com/SXUSongJH/Diffusion_anime_faces_generation.git

# Navigate to project directory
cd Diffusion_anime_faces_generation

# Install dependencies
pip install -r requirements.txt

# Navigate to main directory
cd main

# Run the training script
python run_animefaces.py
```

## Dataset

We utilize the `anime-faces` dataset from Hugging Face, which contains a diverse collection of anime character portraits. The dataset is well-suited for training generative models and contains high-quality anime face illustrations.

Dataset Details:
- Source: [anime-faces dataset on Hugging Face](https://huggingface.co/datasets/jlbaker361/anime_faces_dim_128_50k)
- Resolution: 128x128 pixels
- Size: 50,000 images

## Sample Images from Dataset

Below are some example images from our training dataset:

![Sample Images](assets/image_examples.png)

## Diffusion Process Visualization

We visualized both the forward noising process and the reverse denoising process of our Diffusion model. These visualizations help understand how the model gradually adds or removes noise from the images:

### Forward Noising Process
![Noising Process](assets/noising_images.png)

### Reverse Denoising Process
![Denoising Process](assets/denosing_samples.png)

## Training Details and Results

The model was trained with the following specifications:
- Hardware: 8Ã— NVIDIA RTX 3090 GPUs
- Training Duration: 300 epochs

Below are samples generated by our trained model:

![Generated Samples](assets/generated_samples.png)

## Current Limitations and Future Improvements

While the current results are promising, there are some noticeable imperfections in the generated images. We believe these could be addressed by:
- Increasing the number of training epochs beyond the current 300
- This would likely lead to better quality and more consistent image generation

Note: The current results demonstrate the potential of the approach, but further training would help achieve higher quality outputs.